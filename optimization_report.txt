Steps Taken to Parallelize the Algorithm

1. Sequential Implementation
Initially, the algorithm was implemented sequentially. It works by marking all multiples of each prime number as non-prime. The Sieve of Eratosthenes algorithm iterates from 2 to sqrt(n) and marks the multiples of each prime number.
The sequential version runs in O(n log log n) time complexity, where n is the upper limit for finding prime numbers. This version processes each number one by one, which results in relatively slow execution for large values of n.

2. Identifying Opportunities for Parallelization
The algorithm has two key steps that are inherently parallelizable:
Marking multiples of each prime as non-prime: The marking of multiples can be done independently for each prime, meaning that different numbers can be marked in parallel.
Iterating through numbers: Each prime number can be processed independently (i.e., each iteration to mark multiples does not depend on other iterations).
These observations made it clear that parallelizing the marking step would be beneficial, especially for large values of n.

3. Parallelizing with OpenMP
Step 1: Parallelizing the Outer Loop
The outer loop iterates over numbers from 2 to sqrt(n). We applied OpenMP's #pragma omp parallel for directive to this loop. This allowed each prime number check to run on different threads, which speeds up the overall process.

Step 2: Parallelizing the Inner Loop (Marking Multiples)
The next optimization involved parallelizing the inner loop, where we mark multiples of each prime as non-prime. Each thread was assigned a range of numbers to mark as non-prime, reducing the workload on each thread and allowing the algorithm to run faster.

Step 3: Reducing Overhead
To avoid excessive thread synchronization overhead, the algorithm was optimized to limit the number of threads involved, matching the number of available CPU cores. We used omp_get_num_threads() to adjust the workload dynamically based on the systemâ€™s configuration.


4. Benchmarking and Performance Testing
The performance of both the sequential and OpenMP versions was measured and compared. We ran benchmarks for values of n ranging from 10, 100, 1000, 10000, 100000, 1000000, 10000000, 100000000, and 1000000000.

The execution times were logged for both versions of the algorithm, and the results were saved in a benchmark.txt file for further analysis.